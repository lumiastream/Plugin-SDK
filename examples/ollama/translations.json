{
	"en": {
		"connection": "Connection",
		"Connection": "Connection",
		"Advanced": "Advanced",
		"Advanced Tuning": "Advanced Tuning",
		"Base URL": "Base URL",
		"Your Ollama server URL.": "Your Ollama server URL.",
		"Default Model": "Default Model",
		"Auto (first available)": "Auto (first available)",
		"Loaded from Ollama /api/tags. Leave blank for auto-detect or type a custom model.": "Loaded from Ollama /api/tags. Leave blank for auto-detect or type a custom model.",
		"Default System Message": "Default System Message",
		"Optional system message used when none is provided in the action.": "Optional system message used when none is provided in the action.",
		"Optional controls for sampling, memory, and output behavior.": "Optional controls for sampling, memory, and output behavior.",
		"Default Temperature": "Default Temperature",
		"Optional. Higher is more creative.": "Optional. Higher is more creative.",
		"Default Top P": "Default Top P",
		"Optional nucleus sampling value.": "Optional nucleus sampling value.",
		"Default Max Tokens": "Default Max Tokens",
		"Optional. Maps to Ollama num_predict.": "Optional. Maps to Ollama num_predict.",
		"Keep Alive": "Keep Alive",
		"How long to keep the model loaded (example: `5m`, `0`). Optional.": "How long to keep the model loaded (example: `5m`, `0`). Optional.",
		"Request Timeout (ms)": "Request Timeout (ms)",
		"How long to wait for a response. Set to 0 to disable timeout.": "How long to wait for a response. Set to 0 to disable timeout.",
		"Remember Messages": "Remember Messages",
		"Store history per thread or username.": "Store history per thread or username.",
		"Max History Messages": "Max History Messages",
		"How many recent messages to keep per thread/user.": "How many recent messages to keep per thread/user.",
		"Max Output Length (chars)": "Max Output Length (chars)",
		"Trim responses to this length (0 = no limit).": "Trim responses to this length (0 = no limit).",
		"Ollama Prompt": "Ollama Prompt",
		"Use {{ollama_prompt=message|thread|model}} to return a response from Ollama.": "Use {{ollama_prompt=message|thread|model}} to return a response from Ollama.",
		"Ollama JSON": "Ollama JSON",
		"Use {{ollama_json=message|thread|model}} to return JSON-only output.": "Use {{ollama_json=message|thread|model}} to return JSON-only output.",
		"Ollama One Line": "Ollama One Line",
		"Use {{ollama_one_line=message|thread|model}} to return a single-line response.": "Use {{ollama_one_line=message|thread|model}} to return a single-line response.",
		"Ollama Prompt (No Store)": "Ollama Prompt (No Store)",
		"Use {{ollama_prompt_nostore=message|thread|model}} to run without history.": "Use {{ollama_prompt_nostore=message|thread|model}} to run without history.",
		"Ollama Clear Thread": "Ollama Clear Thread",
		"Use {{ollama_prompt_clear=thread_name}} to clear a conversation thread.": "Use {{ollama_prompt_clear=thread_name}} to clear a conversation thread."
	}
}
